{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Полезные функции"
      ],
      "metadata": {
        "id": "4jJw2ga1LvIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit datamol molfeat xgboost catboost joblib"
      ],
      "metadata": {
        "id": "lbnqMsUw-Bjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -U lightautoml"
      ],
      "metadata": {
        "id": "zajn2H95By8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9hlhELK1OL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from rdkit import DataStructs\n",
        "from rdkit.Chem import AllChem, Draw, Descriptors\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "\n",
        "def mol_dsc_calc(mols):\n",
        "    return pd.DataFrame({k: f(Chem.MolFromSmiles(m)) for k, f in descriptors.items()} for m in mols.values)\n",
        "\n",
        "# список конституционных и физико-химических дескрипторов из библиотеки RDKit\n",
        "descriptors = {\"HeavyAtomCount\": Descriptors.HeavyAtomCount,\n",
        "               \"NHOHCount\": Descriptors.NHOHCount,\n",
        "               \"NOCount\": Descriptors.NOCount,\n",
        "               \"NumHAcceptors\": Descriptors.NumHAcceptors,\n",
        "               \"NumHDonors\": Descriptors.NumHDonors,\n",
        "               \"NumHeteroatoms\": Descriptors.NumHeteroatoms,\n",
        "               \"NumRotatableBonds\": Descriptors.NumRotatableBonds,\n",
        "               \"NumValenceElectrons\": Descriptors.NumValenceElectrons,\n",
        "               \"NumAromaticRings\": Descriptors.NumAromaticRings,\n",
        "               \"NumAliphaticHeterocycles\": Descriptors.NumAliphaticHeterocycles,\n",
        "               \"RingCount\": Descriptors.RingCount,\n",
        "               \"MW\": Descriptors.MolWt,\n",
        "               \"LogP\": Descriptors.MolLogP,\n",
        "               \"MR\": Descriptors.MolMR,\n",
        "               \"TPSA\": Descriptors.TPSA,\n",
        "               \"Molecular Weight\": Descriptors.MolWt}\n",
        "\n",
        "def rdkit_fp(smiles_column: pd.Series, radius=3, nBits=2048, useChirality=False):\n",
        "    # morganFP_rdkit\n",
        "    def desc_gen(mol):\n",
        "        mol = Chem.MolFromSmiles(mol)\n",
        "        bit_vec = np.zeros((1,), np.int16)\n",
        "        DataStructs.ConvertToNumpyArray(\n",
        "            AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=nBits, useChirality=useChirality), bit_vec)\n",
        "        return bit_vec\n",
        "\n",
        "    return pd.DataFrame.from_records(smiles_column.apply(func=desc_gen), columns=[f'bit_id_{i}' for i in range(nBits)])\n",
        "\n",
        "\n",
        "def rdkit_2d(smiles_column: pd.Series):\n",
        "    # 2d_rdkit\n",
        "    descriptors = {i[0]: i[1] for i in Descriptors._descList}\n",
        "    return pd.DataFrame({k: f(Chem.MolFromSmiles(m)) for k, f in descriptors.items()} for m in smiles_column)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_smiles(raw_data: pd.DataFrame, smiles: pd.Series, add_bit_vec: bool=True, add_2d_rdkit: bool=False) -> pd.DataFrame:\n",
        "\n",
        "    data = raw_data.copy()\n",
        "    columns = data.columns\n",
        "\n",
        "    descriptors_transformer = FunctionTransformer(mol_dsc_calc)\n",
        "    X = descriptors_transformer.transform(smiles)\n",
        "    data = data.join(X)\n",
        "\n",
        "    if add_bit_vec:\n",
        "        Y = rdkit_fp(smiles)\n",
        "        data = data.join(Y)\n",
        "\n",
        "    if add_2d_rdkit:\n",
        "        Z = rdkit_2d(smiles)\n",
        "        data = data.join(Z)\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "P0y4oiqt1kIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_hist(data, features, width=5):\n",
        "  figure, axes = plt.subplots(ncols=2, nrows=len(features), figsize=(width, width*len(features)))\n",
        "  for i, name in enumerate(features):\n",
        "      axes[i, 0].set_title(name)\n",
        "      sns.histplot(data[name], ax=axes[i, 0])\n",
        "      axes[i, 1].set_title(name)\n",
        "      sns.scatterplot(data[name], ax=axes[i, 1])"
      ],
      "metadata": {
        "id": "KQq-MDBWaUHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cut_quantiles(raw_data: pd.DataFrame, cols_to_cut: list=None, q_min: float=0.25, q_max: float=0.75) -> pd.DataFrame:\n",
        "\n",
        "    data = raw_data.copy()\n",
        "\n",
        "    quant1 = data[cols_to_cut].quantile(q_min)\n",
        "    quant2 = data[cols_to_cut].quantile(q_max)\n",
        "    quants = pd.concat([quant1, quant2], axis=1)\n",
        "\n",
        "    for name in quants.index:\n",
        "        data = data[quants.loc[name, q_min] <= data[name]]\n",
        "        data = data[data[name] <= quants.loc[name, q_max]]\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "E_1vaIi_2G0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(data):\n",
        "    import pandas as pd\n",
        "    from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "    cat_cols = [\"Strain\", \"Cell\"]\n",
        "    encoder = OneHotEncoder()\n",
        "\n",
        "    # Fit and transform the categorical features\n",
        "    encoded_data = encoder.fit_transform(data[cat_cols]).toarray()\n",
        "\n",
        "    # Create a DataFrame with the one-hot encoded columns\n",
        "    encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out())\n",
        "\n",
        "    # Concatenate the original dataset and the encoded dataset\n",
        "    df_encoded = pd.concat([data, encoded_df], axis=1)\n",
        "\n",
        "    # Drop original categorical columns\n",
        "    df_encoded.drop(cat_cols, axis=1, inplace=True)\n",
        "    joblib.dump(encoder, 'onehot_encoder_cc50.joblib')\n",
        "    return df_encoded"
      ],
      "metadata": {
        "id": "qcmoPwkbMRSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale(data):\n",
        "    from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "    scaler = MinMaxScaler()\n",
        "    target_scaler = StandardScaler()\n",
        "    cols = [\"MW\",\t\"LogP\",\t\"MR\",\t\"TPSA\",\t\"Molecular Weight\"]\n",
        "    data_buf = data.copy()\n",
        "    scaler.fit(data_buf[cols])\n",
        "    y = pd.DataFrame(target_scaler.fit_transform(pd.DataFrame(data_buf[\"Standard Value\"])), columns=[\"Standard Value\"])\n",
        "    X = pd.DataFrame(scaler.transform(data_buf[cols]), columns=cols)\n",
        "    data_buf[cols] = X\n",
        "    data_buf[\"Standard Value\"] = y\n",
        "    joblib.dump(scaler, 'scaler_cc50.joblib')\n",
        "    joblib.dump(target_scaler, 'target_scaler_cc50.joblib')\n",
        "    return data"
      ],
      "metadata": {
        "id": "UCkjJsvYM4Gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Подготовка датасета"
      ],
      "metadata": {
        "id": "ChycD8qJL1-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/ic50_df1 (1).csv\")\n",
        "smiles = data['Smiles']\n",
        "data.drop(columns=[\"Smiles\", \"DOI\"], inplace=True)\n",
        "df_encoded = encode(data)\n",
        "# data = data[data[\"Standard Value\"] <= 0.3]\n",
        "data_extract = extract_smiles(df_encoded, smiles)\n",
        "data_extract.to_csv(\"ic50_extracted.csv\", index=False)"
      ],
      "metadata": {
        "id": "mHBSew3D0Z4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_quant = cut_quantiles(data_extract, cols_to_cut=[\"MW\",\t\"LogP\",\t\"MR\",\t\"TPSA\",\t\"Molecular Weight\"], q_min=0.03, q_max=0.97) #Мажквантильный размах\n",
        "data_scale = scale(data_quant) # Стандартизация"
      ],
      "metadata": {
        "id": "-VWbUTuW1qQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(data_extract[\"Standard Value\"].iloc[:500])"
      ],
      "metadata": {
        "id": "shqY4c-wXuwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Обучение моделей"
      ],
      "metadata": {
        "id": "uk4q5VisNSWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CatBoost и XGBoost"
      ],
      "metadata": {
        "id": "ONHXtF-fNVjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "y = data_scale[\"Standard Value\"]\n",
        "X = data_scale.drop(columns=[\"Standard Value\"])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=42)"
      ],
      "metadata": {
        "id": "Nq8xb2xOAZHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "eval_set = [(X_train, y_train), (X_val, y_val)]\n",
        "reg_xgboost = XGBRegressor(n_estimators=1500, max_depth=50, learning_rate=0.05, early_stopping_rounds=100)\n",
        "reg_xgboost.fit(X_train, y_train, eval_set=eval_set, verbose=False)\n",
        "print(reg_xgboost.score(X_test, y_test))\n",
        "joblib.dump(reg_xgboost, 'reg_ic50_xgboost_1.joblib')"
      ],
      "metadata": {
        "id": "zmjK86L29-z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostRegressor\n",
        "\n",
        "reg_catboost = CatBoostRegressor(iterations=1000, learning_rate=0.02, early_stopping_rounds=5)\n",
        "reg_catboost.fit(X_train, y_train, logging_level=\"Silent\", eval_set=(X_val, y_val), plot=True, plot_file=\"graph.txt\")\n",
        "print(reg_catboost.score(X_test, y_test))\n",
        "joblib.dump(reg_catboost, 'reg_cc50_catboost_1.joblib')"
      ],
      "metadata": {
        "id": "dnufnsZtENg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LightAutoML"
      ],
      "metadata": {
        "id": "y7yxKaTdNalk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
        "from lightautoml.tasks import Task\n",
        "import torch"
      ],
      "metadata": {
        "id": "JG7VuZCtqyxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "cols = list(data_scale.columns)\n",
        "\n",
        "X = data_scale[cols]\n",
        "df_train, df_test = train_test_split(X, random_state=42)\n",
        "\n",
        "y_true = df_test[\"Standard Value\"]\n",
        "df_test.drop(columns=[\"Standard Value\"])\n",
        "automl = TabularAutoML(\n",
        "    task = Task(\n",
        "        name = 'reg',\n",
        "        metric = r2_score),\n",
        "    timeout=1000\n",
        ")\n",
        "oof_pred = automl.fit_predict(\n",
        "    df_train,\n",
        "    roles = {'target': \"Standard Value\"}\n",
        ")\n",
        "torch.save(automl, \"model.pt\")\n",
        "test_pred = automl.predict(df_test)"
      ],
      "metadata": {
        "id": "Cix9PlWZqaUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(automl, 'automl_cc50.joblib')"
      ],
      "metadata": {
        "id": "4GBnC1FvNtH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
        "\n",
        "# test_pred_1 = test_pred.data\n",
        "# y_true_1 = y_true.to_numpy()\n",
        "print(\"r2_score: \", r2_score(y_true_1, test_pred_1))\n",
        "print(\"mean_absolute_error:\", mean_absolute_error(y_true_1, test_pred_1))\n",
        "print(\"mean_absolute_percentage_error:\", mean_absolute_percentage_error(y_true_1, test_pred_1))"
      ],
      "metadata": {
        "id": "A7Z2rEeIzHHF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}